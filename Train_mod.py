import math
import collections
from sklearn.metrics import average_precision_score
from sklearn.model_selection import cross_val_score
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score,recall_score
from sklearn.metrics import roc_auc_score,roc_curve
from sklearn.metrics import auc
import numpy as np
from sklearn.tree import DecisionTreeClassifier
import pandas as pd
import re
from publicsuffixlist import PublicSuffixList
import sys
from sklearn import preprocessing 
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import keras
from keras.models import Sequential
from keras.layers import Dense
from sklearn import metrics
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import classification_report
from mlxtend.plotting import plot_confusion_matrix
import matplotlib.pyplot as plt

class train_c:

	def train_f(self,file_path):
		df=pd.read_csv(file_path)
		print("File Loaded")
		topLevelDomain = []
		with open('D:\\Malware_Detection\\tlds-alpha-by-domain.txt', 'r') as content:
			for line in content:
				topLevelDomain.append((line.strip('\n')))
		psl = PublicSuffixList()
		self.fil_data(df,psl,topLevelDomain)
		print("Filtered Data")
		X_train, X_test, y_train, y_test = self.split_data(df)
		print("Split Data")
		classifier = self.train_and_save(X_train, X_test, y_train, y_test)
		print("Trained and saved model")
		self.pre_and_accu(X_train, X_test, y_train, y_test,classifier)



	def fil_data(self,df,psl,topLevelDomain):
		df = self.extract_features(df,psl,topLevelDomain)
		label_encoder = preprocessing.LabelEncoder() 
		label_encoder.fit(df['DGA_family'])
		np.save('DGA_family_classes.npy', label_encoder.classes_)
		df['DGA_family']= label_encoder.transform(df['DGA_family'])
		df['Domain']= label_encoder.fit_transform(df['Domain']) 
		df['Type']= label_encoder.fit_transform(df['Type']) 
		df.drop(columns=["Domain"],axis=1,inplace=True)
		df.dropna()
		df.fillna(df.mean(), inplace=True)

	def split_data(self,df):
		X = df.drop(columns='Type',axis=1) # here we have 2 variables for multiple regression. If you just want to use one variable for simple linear regression, then use X = df['Interest_Rate'] for example.Alternatively, you may add additional variables within the brackets
		Y=df[["Type"]]
		X = X.values.astype(np.float)
		Y = Y.values.astype(np.float)
		X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)
		return X_train, X_test, y_train, y_test


	def train_and_save(self,X_train, X_test, y_train, y_test):
		classifier = Sequential()
		#Adding Input and first hidden layer
		classifier.add(Dense(activation="relu", input_dim=17, units=8, kernel_initializer="uniform"))
		#Adding second hidden layer
		classifier.add(Dense(activation="relu", units=8, kernel_initializer="uniform"))

		#Adding the output layer
		classifier.add(Dense(activation="sigmoid", units=1, kernel_initializer="uniform"))

		#Compile the ANN
		classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

		#Fitting the ANN to the training set
		classifier.fit(X_train,y_train, batch_size = 10, epochs = 10)

		classifier.save("D:\\Malware_Detection\\ANN_Model")
		return classifier

	def pre_and_accu(self,X_train, X_test, y_train, y_test,classifier):
		y_pred=classifier.predict(X_test)
		y_pred = y_pred>0.5
		print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
		precision_recall_fscore_support(y_test, y_pred, average='macro')
		precision_recall_fscore_support(y_test, y_pred, average=None,labels=[0,1])
		
		# actual values
		actual = y_test
		# predicted values
		predicted =y_pred

		# confusion matrix
		matrixresult = confusion_matrix(actual,predicted, labels=[1,0])
		print('Confusion matrix : \n',matrixresult)

		# outcome values order in sklearn
		tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)
		print('Outcome values : \n', tp, fn, fp, tn)

		# classification report for precision, recall f1-score and accuracy
		matrix = classification_report(actual,predicted,labels=[1,0])
		print('Classification report : \n',matrix)
		binary1 = np.array(matrixresult)

		fig, ax = plot_confusion_matrix(conf_mat=binary1)
		plt.savefig('foo.png')





	def domain_length(self,domain):
		# Generate Domain Name Length (DNL)
		return len(domain)

	def subdomains_number(self,domain,psl):
		# Generate Number of Subdomains (NoS)
		subdomain = self.ignoreVPS(domain,psl)
		return (subdomain.count('.') + 1)

	def subdomain_length_mean(self,domain,psl):
		# enerate Subdomain Length Mean (SLM) 
		subdomain = self.ignoreVPS(domain,psl)
		result = (len(subdomain) - subdomain.count('.')) / (subdomain.count('.') + 1)
		return result

	def has_www_prefix(self,domain):
		# Generate Has www Prefix (HwP)
		if domain.split('.')[0] == 'www':
			return 1
		else:
			return 0

	def underscore_ratio(self,domain,psl):
		# Generate Underscore Ratio (UR) on dataset
		subString = self.ignoreVPS(domain,psl)
		result = subString.count('_') / (len(subString) - subString.count('.'))
		return result

	def ignoreVPS(self,domain,psl):
		# Return the rest of domain after ignoring the Valid Public Suffixes:
		validPublicSuffix = '.' + psl.publicsuffix(domain)
		if len(validPublicSuffix) < len(domain):
			# If it has VPS
			subString = domain[0: domain.index(validPublicSuffix)]  
		elif len(validPublicSuffix) == len(domain):
			return 0
		else:
			# If not
			subString = domain
		
		return subString

	def contains_digit(self,domain,psl):
		"""
		Contains Digits 
		"""
		subdomain = self.ignoreVPS(domain,psl)
		for item in subdomain:
			if item.isdigit():
				return 1
		return 0

	def vowel_ratio(self,domain,psl):
		"""
		calculate Vowel Ratio 
		"""
		VOWELS = set('aeiou')
		v_counter = 0
		a_counter = 0
		subdomain = self.ignoreVPS(domain,psl)
		for item in subdomain:
			if item.isalpha():
				a_counter+=1
			if item in VOWELS:
				v_counter+=1
		if a_counter>1:
			ratio = v_counter/a_counter
			return ratio

	def contains_IP_address(self,domain):
		# Generate Contains IP Address (CIPA) on datasetx
		splitSet = domain.split('.')
		for element in splitSet:
			if(re.match("\d+", element)) == None:
				return 0
		return 1 
		
	def digit_ratio(self,domain,psl):
		"""
		calculate digit ratio
		"""
		d_counter = 0
		counter = 0
		subdomain = self.ignoreVPS(domain,psl)
		for item in subdomain:
			if item.isalpha() or item.isdigit():
				counter+=1
			if item.isdigit():
				d_counter+=1
		if counter>1:
			ratio = d_counter/counter
			return ratio

	def typeTo_Binary(self,type):
		# Convert Type to Binary variable DGA = 1, Normal = 0
		if type == 'DGA':
			return 1
		else:
			return 0

	def contains_single_character_subdomain(self,domain,psl):
	# Generate Contains Single-Character Subdomain (CSCS) 
		domain = self.ignoreVPS(domain,psl)
		str_split = domain.split('.')
		minLength = len(str_split[0])
		for i in range(0, len(str_split) - 1):
			minLength = len(str_split[i]) if len(str_split[i]) < minLength else minLength
		if minLength == 1:
			return 1
		else:
			return 0
		
	def contains_TLD_subdomain(self,domain,psl,topLevelDomain):
	# Generate Contains TLD as Subdomain (CTS)
		subdomain = self.ignoreVPS(domain,psl)
		str_split = subdomain.split('.')
		for i in range(0, len(str_split) - 1):
			if str_split[i].upper() in topLevelDomain:
				return 1
		return 0

	def prc_rrc(self,domain,psl):
		"""
		calculate the Ratio of Repeated Characters in a subdomain
		"""
		subdomain = self.ignoreVPS(domain,psl)
		subdomain = re.sub("[.]", "", subdomain)
		char_num=0
		repeated_char_num=0
		d = collections.defaultdict(int)
		for c in list(subdomain):
			d[c] += 1
		for item in d:
			char_num +=1
			if d[item]>1:
				repeated_char_num +=1
		ratio = repeated_char_num/char_num
		return ratio

	def prc_rcc(self,domain,psl):
		"""
		calculate the Ratio of Consecutive Consonants
		"""
		VOWELS = set('aeiou')
		counter = 0
		cons_counter=0
		subdomain = self.ignoreVPS(domain,psl)
		for item in subdomain:
			i = 0
			if item.isalpha() and item not in VOWELS:
				counter+=1
			else:
				if counter>1:
					cons_counter+=counter
				counter=0
			i+=1
		if i==len(subdomain) and counter>1:
			cons_counter+=counter
		ratio = cons_counter/len(subdomain)
		return ratio

	def prc_rcd(self,domain,psl):
		"""
		calculate the ratio of consecutive digits
		"""
		counter = 0
		digit_counter=0
		subdomain = self.ignoreVPS(domain,psl)
		for item in subdomain:
			i = 0
			if item.isdigit():
				counter+=1
			else:
				if counter>1:
					digit_counter+=counter
				counter=0
			i+=1
		if i==len(subdomain) and counter>1:
			digit_counter+=counter
		ratio = digit_counter/len(subdomain)
		return ratio

	def has_hvltd(self,domain,topLevelDomain):
		# Generate Has a Valid Top Level Domain (HVTLD)
		if domain.split('.')[len(domain.split('.')) - 1].upper() in topLevelDomain:
			return 1
		else:
			return 0

	def prc_entropy(self,domain,psl):
		"""
		calculate the entropy of subdomain
		:param domain_str: subdomain
		:return: the value of entropy
		"""
		subdomain = self.ignoreVPS(domain,psl)
		# get probability of chars in string
		prob = [float(subdomain.count(c)) / len(subdomain) for c in dict.fromkeys(list(subdomain))]

		# calculate the entropy
		entropy = - sum([p * math.log(p) / math.log(2.0) for p in prob])
		return entropy

	def extract_features(self,df,psl,topLevelDomain):
		df['DNL'] = df['Domain'].apply(lambda x: self.domain_length(x))
		df['NoS'] = df['Domain'].apply(lambda x: self.subdomains_number(x,psl))
		df['SLM'] = df['Domain'].apply(lambda x: self.subdomain_length_mean(x,psl))
		df['HwP'] = df['Domain'].apply(lambda x: self.has_www_prefix(x))
		df['HVTLD'] = df['Domain'].apply(lambda x: self.has_hvltd(x,topLevelDomain))
		df['CSCS'] = df['Domain'].apply(lambda x: self.contains_single_character_subdomain(x,psl))
		df['CTS'] = df['Domain'].apply(lambda x: self.contains_TLD_subdomain(x,psl,topLevelDomain))
		df['UR'] = df['Domain'].apply(lambda x: self.underscore_ratio(x,psl))
		df['CIPA'] = df['Domain'].apply(lambda x: self.contains_IP_address(x))
		df['contains_digit']= df['Domain'].apply(lambda x: self.contains_digit(x,psl))
		df['vowel_ratio']= df['Domain'].apply(lambda x: self.vowel_ratio(x,psl))
		df['digit_ratio']= df['Domain'].apply(lambda x: self.digit_ratio(x,psl))
		df['RRC']= df['Domain'].apply(lambda x: self.prc_rrc(x,psl))
		df['RCC']= df['Domain'].apply(lambda x: self.prc_rcc(x,psl))
		df['RCD']= df['Domain'].apply(lambda x: self.prc_rcd(x,psl))
		df['Entropy']= df['Domain'].apply(lambda x: self.prc_entropy(x,psl))
		return df
    















